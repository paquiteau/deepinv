
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/unfolded/demo_DEQ.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_unfolded_demo_DEQ.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_unfolded_demo_DEQ.py:


Deep Equilibrium (DEQ) algorithms for image deblurring
====================================================================================================

This a toy example to show you how to use DEQ to solve a deblurring problem. 
Note that this is a small dataset for training. For optimal results, use a larger dataset.
For visualizing the training, you can use Weight&Bias (wandb) by setting ``wandb_vis=True``.

For now DEQ is only possible with PGD, HQS and GD optimization algorithms. 

.. GENERATED FROM PYTHON SOURCE LINES 12-25

.. code-block:: Python


    import deepinv as dinv
    from pathlib import Path
    import torch
    from torch.utils.data import DataLoader
    from deepinv.models import DnCNN
    from deepinv.optim.data_fidelity import L2
    from deepinv.optim.prior import PnP
    from deepinv.unfolded import DEQ_builder
    from deepinv.training import train, test
    from torchvision import transforms
    from deepinv.utils.demo import load_dataset








.. GENERATED FROM PYTHON SOURCE LINES 26-29

Setup paths for data loading and results.
----------------------------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 29-41

.. code-block:: Python


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 42-45

Load base image datasets and degradation operators.
----------------------------------------------------------------------------------------
In this example, we use the CBSD500 dataset and the Set3C dataset for testing.

.. GENERATED FROM PYTHON SOURCE LINES 45-68

.. code-block:: Python


    img_size = 32
    n_channels = 3  # 3 for color images, 1 for gray-scale images
    operation = "deblurring"
    # For simplicity, we use a small dataset for training.
    # To be replaced for optimal results. For example, you can use the larger "drunet" dataset.
    train_dataset_name = "CBSD500"
    test_dataset_name = "set3c"
    # Generate training and evaluation datasets in HDF5 folders and load them.
    test_transform = transforms.Compose(
        [transforms.CenterCrop(img_size), transforms.ToTensor()]
    )
    train_transform = transforms.Compose(
        [transforms.RandomCrop(img_size), transforms.ToTensor()]
    )
    train_base_dataset = load_dataset(
        train_dataset_name, ORIGINAL_DATA_DIR, transform=train_transform
    )
    test_base_dataset = load_dataset(
        test_dataset_name, ORIGINAL_DATA_DIR, transform=test_transform
    )









.. GENERATED FROM PYTHON SOURCE LINES 69-72

Generate a dataset of low resolution images and load it.
----------------------------------------------------------------------------------------
We use the Downsampling class from the physics module to generate a dataset of low resolution images.

.. GENERATED FROM PYTHON SOURCE LINES 72-107

.. code-block:: Python



    # Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous
    # dataloading.
    num_workers = 4 if torch.cuda.is_available() else 0

    # Degradation parameters
    noise_level_img = 0.03

    # Generate the gaussian blur downsampling operator.
    physics = dinv.physics.BlurFFT(
        img_size=(n_channels, img_size, img_size),
        filter=dinv.physics.blur.gaussian_blur(),
        device=device,
        noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),
    )
    my_dataset_name = "demo_DEQ"
    n_images_max = (
        1000 if torch.cuda.is_available() else 10
    )  # maximal number of images used for training
    measurement_dir = DATA_DIR / train_dataset_name / operation
    generated_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_base_dataset,
        test_dataset=test_base_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        num_workers=num_workers,
        dataset_filename=str(my_dataset_name),
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Dataset has been saved in measurements/CBSD500/deblurring




.. GENERATED FROM PYTHON SOURCE LINES 108-114

Define the  DEQ algorithm.
----------------------------------------------------------------------------------------
We use the helper function :meth:`deepinv.unfolded.DEQ_builder` to defined the DEQ architecture.
The chosen algorithm is here HQS (Half Quadratic Splitting).
Note for DEQ, the prior and regularization parameters should be common for all iterations
to keep a constant fixed-point operator.

.. GENERATED FROM PYTHON SOURCE LINES 114-160

.. code-block:: Python



    # Select the data fidelity term
    data_fidelity = L2()

    # Set up the trainable denoising prior
    denoiser = DnCNN(in_channels=3, out_channels=3, depth=7, device=device, pretrained=None)

    # Here the prior model is common for all iterations
    prior = PnP(denoiser=denoiser)

    # Unrolled optimization algorithm parameters
    max_iter = 20 if torch.cuda.is_available() else 10
    stepsize = 1.0  # Initial value for the stepsize. A single stepsize is common for each iterations.
    sigma_denoiser = 0.03  # Initial value for the denoiser parameter. A single value is common for each iterations.
    anderson_acceleration_forward = True  # use Anderson acceleration for the forward pass.
    anderson_acceleration_backward = (
        True  # use Anderson acceleration for the backward pass.
    )
    anderson_history_size = (
        5 if torch.cuda.is_available() else 3
    )  # history size for Anderson acceleration.

    params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary
        "stepsize": stepsize,
        "g_param": sigma_denoiser,
    }
    trainable_params = [
        "stepsize",
        "g_param",
    ]  # define which parameters from 'params_algo' are trainable

    # Define the unfolded trainable model.
    model = DEQ_builder(
        iteration="HQS",  # For now DEQ is only possible with PGD, HQS and GD optimization algorithms.
        params_algo=params_algo.copy(),
        trainable_params=trainable_params,
        data_fidelity=data_fidelity,
        max_iter=max_iter,
        prior=prior,
        anderson_acceleration=anderson_acceleration_forward,
        anderson_acceleration_backward=anderson_acceleration_backward,
        history_size_backward=anderson_history_size,
        history_size=anderson_history_size,
    )








.. GENERATED FROM PYTHON SOURCE LINES 161-164

Define the training parameters.
-------------------------------
We use the Adam optimizer and the StepLR scheduler.

.. GENERATED FROM PYTHON SOURCE LINES 164-190

.. code-block:: Python



    # training parameters
    epochs = 10
    learning_rate = 5e-4
    train_batch_size = 32 if torch.cuda.is_available() else 1
    test_batch_size = 3

    # choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))

    # choose supervised training loss
    losses = [dinv.loss.SupLoss(metric=dinv.metric.mse())]

    # Logging parameters
    verbose = True
    wandb_vis = False  # plot curves and images in Weight&Bias

    train_dataloader = DataLoader(
        train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True
    )
    test_dataloader = DataLoader(
        test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False
    )








.. GENERATED FROM PYTHON SOURCE LINES 191-194

Train the network
-----------------
We train the network using the library's train function.

.. GENERATED FROM PYTHON SOURCE LINES 194-213

.. code-block:: Python


    trainer = dinv.Trainer(
        model=model,
        physics=physics,
        epochs=epochs,
        scheduler=scheduler,
        device=device,
        losses=losses,
        optimizer=optimizer,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.
        wandb_vis=wandb_vis,  # training visualization can be done in Weight&Bias
    )

    model = trainer.train()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 188165 trainable parameters
    Train epoch 0: TotalLoss=3.312, PSNR=-2.526
    Eval epoch 0: PSNR=-13.571
    Train epoch 1: TotalLoss=99.056, PSNR=-13.819
    Eval epoch 1: PSNR=-5.116
    Train epoch 2: TotalLoss=1.328, PSNR=0.082
    Eval epoch 2: PSNR=-2.012
    Train epoch 3: TotalLoss=1.131, PSNR=0.57
    Eval epoch 3: PSNR=-2.777
    Train epoch 4: TotalLoss=1.207, PSNR=0.256
    Eval epoch 4: PSNR=-3.249
    Train epoch 5: TotalLoss=1.275, PSNR=0.071
    Eval epoch 5: PSNR=-3.396
    Train epoch 6: TotalLoss=1.288, PSNR=0.016
    Eval epoch 6: PSNR=-3.449
    Train epoch 7: TotalLoss=1.293, PSNR=-0.005
    Eval epoch 7: PSNR=-3.47
    Train epoch 8: TotalLoss=1.294, PSNR=-0.014
    Eval epoch 8: PSNR=-3.471
    Train epoch 9: TotalLoss=1.294, PSNR=-0.015
    Eval epoch 9: PSNR=-3.471




.. GENERATED FROM PYTHON SOURCE LINES 214-218

Test the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 218-220

.. code-block:: Python


    trainer.test(test_dataloader)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 188165 trainable parameters
    Eval epoch 0: PSNR=-3.471, PSNR no learning=21.125
    Test results:
    PSNR no learning: 21.125 +- 1.207
    PSNR: -3.471 +- 1.100

    {'PSNR no learning': 21.124956766764324, 'PSNR no learning_std': 1.2067533657179195, 'PSNR': -3.4710702896118164, 'PSNR_std': 1.0995518799995156}




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 24.328 seconds)


.. _sphx_glr_download_auto_examples_unfolded_demo_DEQ.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_DEQ.ipynb <demo_DEQ.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_DEQ.py <demo_DEQ.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_DEQ.zip <demo_DEQ.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

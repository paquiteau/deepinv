<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deepinv.optim.data_fidelity &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=35a8b989"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.denoisers.html">Denoisers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.iterative.html">Iterative Reconstruction (PnP, RED, etc.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.unfolded.html">Unfolded Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.sampling.html">Diffusion Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.other_models.html">Other Reconstruction Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.multigpu.html">Using multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">deepinv.optim.data_fidelity</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for deepinv.optim.data_fidelity</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">deepinv.optim.utils</span> <span class="kn">import</span> <span class="n">gradient_descent</span>


<div class="viewcode-block" id="DataFidelity">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity">[docs]</a>
<span class="k">class</span> <span class="nc">DataFidelity</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data fidelity term :math:`\datafid{x}{y}=\distance{\forw{x}}{y}`.</span>

<span class="sd">    This is the base class for the data fidelity term :math:`\datafid{x}{y} = \distance{\forw{x}}{y}` where :math:`A` is a</span>
<span class="sd">    linear or nonlinear operator, :math:`x\in\xset` is a variable , :math:`y\in\yset` is the observation and</span>
<span class="sd">    :math:`\distancename` is a distance function.</span>

<span class="sd">    .. doctest::</span>

<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import deepinv as dinv</span>
<span class="sd">        &gt;&gt;&gt; # define a loss function</span>
<span class="sd">        &gt;&gt;&gt; data_fidelity = dinv.optim.L2()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create a measurement operator</span>
<span class="sd">        &gt;&gt;&gt; A = torch.Tensor([[2, 0], [0, 0.5]])</span>
<span class="sd">        &gt;&gt;&gt; A_forward = lambda v: A @ v</span>
<span class="sd">        &gt;&gt;&gt; A_adjoint = lambda v: A.transpose(0, 1) @ v</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define the physics model associated to this operator</span>
<span class="sd">        &gt;&gt;&gt; physics = dinv.physics.LinearPhysics(A=A_forward, A_adjoint=A_adjoint)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define two points</span>
<span class="sd">        &gt;&gt;&gt; x = torch.Tensor([[1], [4]]).unsqueeze(0)</span>
<span class="sd">        &gt;&gt;&gt; y = torch.Tensor([[1], [1]]).unsqueeze(0)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the loss :math:`f(x) = \datafid{A(x)}{y}`</span>
<span class="sd">        &gt;&gt;&gt; data_fidelity(x, y, physics)</span>
<span class="sd">        tensor([1.0000])</span>
<span class="sd">        &gt;&gt;&gt; # Compute the gradient of :math:`f`</span>
<span class="sd">        &gt;&gt;&gt; grad = data_fidelity.grad(x, y, physics)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the proximity operator of :math:`f`</span>
<span class="sd">        &gt;&gt;&gt; prox = data_fidelity.prox(x, y, physics, gamma=1.0)</span>

<span class="sd">    .. warning::</span>
<span class="sd">        All variables have a batch dimension as first dimension.</span>

<span class="sd">    :param callable d: data fidelity distance function :math:`\distance{u}{y}`. Outputs a tensor of size `B`, the size of the batch. Default: None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_d</span> <span class="o">=</span> <span class="n">d</span>

<div class="viewcode-block" id="DataFidelity.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the data fidelity distance :math:`\distance{u}{y}`.</span>

<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the distance function is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :return: (torch.Tensor) data fidelity :math:`\distance{u}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradient :math:`\nabla_u\distance{u}{y}`, computed in :math:`u`. Note that this is the gradient of</span>
<span class="sd">        :math:`\distancename` and not :math:`\datafidname`. By default, the gradient is computed using automatic differentiation.</span>

<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the gradient is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`u`.</span>
<span class="sd">        :return: (torch.Tensor) gradient of :math:`d` in :math:`u`, i.e. :math:`\nabla_u\distance{u}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">u</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">grad</span></div>


<div class="viewcode-block" id="DataFidelity.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">u</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">stepsize_inter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">max_iter_inter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">tol_inter</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the proximity operator :math:`\operatorname{prox}_{\gamma\distance{\cdot}{y}}(u)`, computed in :math:`u`. Note</span>
<span class="sd">        that this is the proximity operator of :math:`\distancename` and not :math:`\datafidname`. By default, the proximity operator is computed using internal gradient descent.</span>

<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`u`.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float stepsize_inter: stepsize used for internal gradient descent</span>
<span class="sd">        :param int max_iter_inter: maximal number of iterations for internal gradient descent.</span>
<span class="sd">        :param float tol_inter: internal gradient descent has converged when the L2 distance between two consecutive iterates is smaller than tol_inter.</span>
<span class="sd">        :return: (torch.Tensor) proximity operator :math:`\operatorname{prox}_{\gamma\distance{\cdot}{y}}(u)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_d</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gradient_descent</span><span class="p">(</span>
            <span class="n">grad</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize_inter</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter_inter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol_inter</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.forward">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the data fidelity term :math:`\datafid{x}{y} = \distance{\forw{x}}{y}`.</span>

<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the data fidelity is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :return: (torch.Tensor) data fidelity :math:`\datafid{x}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.grad">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.grad">[docs]</a>
    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the gradient of the data fidelity term :math:`\datafidname` at :math:`x`.</span>

<span class="sd">        The gradient is computed using the chain rule:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \nabla_x \distance{\forw{x}}{y} = \left. \frac{\partial A}{\partial x} \right|_x^\top \nabla_u \distance{u}{y},</span>

<span class="sd">        where :math:`\left. \frac{\partial A}{\partial x} \right|_x` is the Jacobian of :math:`A` at :math:`x`, and :math:`\nabla_u \distance{u}{y}` is computed using ``grad_d`` with :math:`u = \forw{x}`. The multiplication is computed using the ``A_vjp`` method of the physics.</span>

<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the gradient is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :return: (torch.Tensor) gradient :math:`\nabla_x \datafid{x}{y}`, computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_vjp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_d</span><span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>


<div class="viewcode-block" id="DataFidelity.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">physics</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">stepsize_inter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">max_iter_inter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">tol_inter</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the proximity operator of :math:`\datafidname` at :math:`x`.</span>

<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float stepsize_inter: stepsize used for internal gradient descent</span>
<span class="sd">        :param int max_iter_inter: maximal number of iterations for internal gradient descent.</span>
<span class="sd">        :param float tol_inter: internal gradient descent has converged when the L2 distance between two consecutive iterates is smaller than tol_inter.</span>
<span class="sd">        :return: (torch.Tensor) proximity operator :math:`\operatorname{prox}_{\gamma \datafidname}(x)`, computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gradient_descent</span><span class="p">(</span>
            <span class="n">grad</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize_inter</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter_inter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol_inter</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.prox_conjugate">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox_conjugate">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_conjugate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the proximity operator of the convex conjugate :math:`(\lambda \datafidname)^*` at :math:`x`,</span>
<span class="sd">        using the Moreau formula.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            This function is only valid for convex :math:`\datafidname`.</span>

<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float lamb: math:`\lambda` parameter in front of :math:`f`</span>
<span class="sd">        :return: (torch.Tensor) proximity operator :math:`\operatorname{prox}_{\gamma (\lambda \datafidname)^*}(x)`,</span>
<span class="sd">            computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox</span><span class="p">(</span>
            <span class="n">x</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">lamb</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.prox_d_conjugate">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox_d_conjugate">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d_conjugate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the proximity operator of the convex conjugate :math:`(\lambda \distancename)^*` at :math:`u`,</span>
<span class="sd">        using the Moreau formula.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            This function is only valid for convex :math:`\distancename`.</span>

<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float lamb: math:`\lambda` parameter in front of :math:`\distancename`</span>
<span class="sd">        :return: (torch.Tensor) proximity operator :math:`\operatorname{prox}_{\gamma (\lambda \distancename)^*}(x)`,</span>
<span class="sd">            computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">u</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span>
            <span class="n">u</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">lamb</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="L2">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2">[docs]</a>
<span class="k">class</span> <span class="nc">L2</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of :math:`\distancename` as the normalized :math:`\ell_2` norm</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = \frac{1}{2\sigma^2}\|\forw{x}-y\|^2</span>

<span class="sd">    It can be used to define a log-likelihood function associated with additive Gaussian noise</span>
<span class="sd">    by setting an appropriate noise level :math:`\sigma`.</span>

<span class="sd">    :param float sigma: Standard deviation of the noise to be used as a normalisation factor.</span>


<span class="sd">    .. doctest::</span>

<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import deepinv as dinv</span>
<span class="sd">        &gt;&gt;&gt; # define a loss function</span>
<span class="sd">        &gt;&gt;&gt; fidelity = dinv.optim.L2()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; x = torch.ones(1, 1, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; mask = torch.ones_like(x)</span>
<span class="sd">        &gt;&gt;&gt; mask[0, 0, 1, 1] = 0</span>
<span class="sd">        &gt;&gt;&gt; physics = dinv.physics.Inpainting(tensor_size=(1, 3, 3), mask=mask)</span>
<span class="sd">        &gt;&gt;&gt; y = physics(x)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the data fidelity f(Ax, y)</span>
<span class="sd">        &gt;&gt;&gt; fidelity(x, y, physics)</span>
<span class="sd">        tensor([0.])</span>
<span class="sd">        &gt;&gt;&gt; # Compute the gradient of f</span>
<span class="sd">        &gt;&gt;&gt; fidelity.grad(x, y, physics)</span>
<span class="sd">        tensor([[[[0., 0., 0.],</span>
<span class="sd">                  [0., 0., 0.],</span>
<span class="sd">                  [0., 0., 0.]]]])</span>
<span class="sd">        &gt;&gt;&gt; # Compute the proximity operator of f</span>
<span class="sd">        &gt;&gt;&gt; fidelity.prox(x, y, physics, gamma=1.0)</span>
<span class="sd">        tensor([[[[1., 1., 1.],</span>
<span class="sd">                  [1., 1., 1.],</span>
<span class="sd">                  [1., 1., 1.]]]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<div class="viewcode-block" id="L2.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the data fidelity distance :math:`\datafid{u}{y}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \datafid{u}{y} = \frac{1}{2\sigma^2}\|u-y\|^2</span>


<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the data fidelity is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :return: (torch.Tensor) data fidelity :math:`\datafid{u}{y}` of size `B` with `B` the size of the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">d</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="n">d</span></div>


<div class="viewcode-block" id="L2.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradient of :math:`\distancename`, that is  :math:`\nabla_{u}\distance{u}{y}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \nabla_{u}\distance{u}{y} = \frac{1}{\sigma^2}(u-y)</span>


<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the gradient is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :return: (torch.Tensor) gradient of the distance function :math:`\nabla_{u}\distance{u}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="L2.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of :math:`\gamma \distance{x}{y} = \frac{\gamma}{2\sigma^2}\|x-y\|^2`.</span>

<span class="sd">        Computes :math:`\operatorname{prox}_{\gamma \distancename}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">           \operatorname{prox}_{\gamma \distancename} = \underset{u}{\text{argmin}} \frac{\gamma}{2\sigma^2}\|u-y\|_2^2+\frac{1}{2}\|u-x\|_2^2</span>


<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param float gamma: thresholding parameter.</span>
<span class="sd">        :return: (torch.Tensor) proximity operator :math:`\operatorname{prox}_{\gamma \distancename}(x)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gamma_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="n">gamma</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">gamma_</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">gamma_</span><span class="p">)</span></div>


<div class="viewcode-block" id="L2.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of :math:`\gamma \datafid{Ax}{y} = \frac{\gamma}{2\sigma^2}\|Ax-y\|^2`.</span>

<span class="sd">        Computes :math:`\operatorname{prox}_{\gamma \datafidname}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">           \operatorname{prox}_{\gamma \datafidname} = \underset{u}{\text{argmin}} \frac{\gamma}{2\sigma^2}\|Au-y\|_2^2+\frac{1}{2}\|u-x\|_2^2</span>


<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :return: (torch.Tensor) proximity operator :math:`\operatorname{prox}_{\gamma \datafidname}(x)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">physics</span><span class="o">.</span><span class="n">prox_l2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="IndicatorL2">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2">[docs]</a>
<span class="k">class</span> <span class="nc">IndicatorL2</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Indicator of :math:`\ell_2` ball with radius :math:`r`.</span>

<span class="sd">    The indicator function of the $\ell_2$ ball with radius :math:`r`, denoted as \iota_{\mathcal{B}_2(y,r)(u)},</span>
<span class="sd">    is defined as</span>

<span class="sd">    .. math::</span>

<span class="sd">          \iota_{\mathcal{B}_2(y,r)}(u)= \left.</span>
<span class="sd">              \begin{cases}</span>
<span class="sd">                0, &amp; \text{if } \|u-y\|_2\leq r \\</span>
<span class="sd">                +\infty &amp; \text{else.}</span>
<span class="sd">              \end{cases}</span>
<span class="sd">              \right.</span>


<span class="sd">    :param float radius: radius of the ball. Default: None.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="o">=</span> <span class="n">radius</span>

<div class="viewcode-block" id="IndicatorL2.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the batched indicator of :math:`\ell_2` ball with radius `radius`, i.e. :math:`\iota_{\mathcal{B}(y,r)}(u)`.</span>

<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the indicator is computed. :math:`u` is assumed to be of shape (B, ...) where B is the batch size.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`u`.</span>
<span class="sd">        :param float radius: radius of the :math:`\ell_2` ball. If `radius` is None, the radius of the ball is set to `self.radius`. Default: None.</span>
<span class="sd">        :return: (torch.Tensor) indicator of :math:`\ell_2` ball with radius `radius`. If the point is inside the ball, the output is 0, else it is 1e16.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="k">if</span> <span class="n">radius</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">radius</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&gt;</span> <span class="n">radius</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e16</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="IndicatorL2.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the indicator of :math:`\ell_2` ball with radius `radius`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\iota_{\mathcal{B}_2(y,r)}}(x) = \operatorname{proj}_{\mathcal{B}_2(y, r)}(x)</span>


<span class="sd">        where :math:`\operatorname{proj}_{C}(x)` denotes the projection on the closed convex set :math:`C`.</span>


<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`x`.</span>
<span class="sd">        :param float gamma: step-size. Note that this parameter is not used in this function.</span>
<span class="sd">        :param float radius: radius of the :math:`\ell_2` ball.</span>
<span class="sd">        :return: (torch.Tensor) projection on the :math:`\ell_2` ball of radius `radius` and centered in `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="k">if</span> <span class="n">radius</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">radius</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="n">diff</span> <span class="o">*</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">radius</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">dist</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">dist</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="IndicatorL2.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">physics</span><span class="p">,</span>
        <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stepsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">crit_conv</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the indicator of :math:`\ell_2` ball with radius `radius`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\gamma \iota_{\mathcal{B}_2(y, r)}(A\cdot)}(x) = \underset{u}{\text{argmin}} \,\, \iota_{\mathcal{B}_2(y, r)}(Au)+\frac{1}{2}\|u-x\|_2^2</span>

<span class="sd">        Since no closed form is available for general measurement operators, we use a dual forward-backward algorithm,</span>
<span class="sd">        as suggested in `Proximal Splitting Methods in Signal Processing &lt;https://arxiv.org/pdf/0912.3522.pdf&gt;`_.</span>

<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`\forw{x}`.</span>
<span class="sd">        :param torch.Tensor radius: radius of the :math:`\ell_2` ball.</span>
<span class="sd">        :param float stepsize: step-size of the dual-forward-backward algorithm.</span>
<span class="sd">        :param float crit_conv: convergence criterion of the dual-forward-backward algorithm.</span>
<span class="sd">        :param int max_iter: maximum number of iterations of the dual-forward-backward algorithm.</span>
<span class="sd">        :param float gamma: factor in front of the indicator function. Notice that this does not affect the proximity</span>
<span class="sd">                            operator since the indicator is scale invariant. Default: None.</span>
<span class="sd">        :return: (torch.Tensor) projection on the :math:`\ell_2` ball of radius `radius` and centered in `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="k">if</span> <span class="n">radius</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">radius</span>

        <span class="k">if</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="ow">and</span> <span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>  <span class="c1"># Identity case</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">radius</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">norm_AtA</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">compute_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">stepsize</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">norm_AtA</span> <span class="k">if</span> <span class="n">stepsize</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">stepsize</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
                <span class="n">u_prev</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_adjoint</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
                <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">u_</span> <span class="o">-</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span>
                    <span class="n">u_</span> <span class="o">/</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">radius</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">)</span>
                <span class="n">rel_crit</span> <span class="o">=</span> <span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_prev</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">rel_crit</span> <span class="o">&lt;</span> <span class="n">crit_conv</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="k">return</span> <span class="n">t</span></div>
</div>



<div class="viewcode-block" id="PoissonLikelihood">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood">[docs]</a>
<span class="k">class</span> <span class="nc">PoissonLikelihood</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Poisson negative log-likelihood.</span>

<span class="sd">    .. math::</span>

<span class="sd">        \datafid{z}{y} =  -y^{\top} \log(z+\beta)+1^{\top}z</span>

<span class="sd">    where :math:`y` are the measurements, :math:`z` is the estimated (positive) density and :math:`\beta\geq 0` is</span>
<span class="sd">    an optional background level.</span>

<span class="sd">    .. note::</span>

<span class="sd">        The function is not Lipschitz smooth w.r.t. :math:`z` in the absence of background (:math:`\beta=0`).</span>

<span class="sd">    :param float bkg: background level :math:`\beta`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">bkg</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bkg</span> <span class="o">=</span> <span class="n">bkg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>

<div class="viewcode-block" id="PoissonLikelihood.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the Poisson negative log-likelihood.</span>

<span class="sd">        :param torch.Tensor x: signal :math:`x` at which the function is computed.</span>
<span class="sd">        :param torch.Tensor y: measurement :math:`y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">y</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bkg</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="PoissonLikelihood.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gradient of the Poisson negative log-likelihood.</span>


<span class="sd">        :param torch.Tensor x: signal :math:`x` at which the function is computed.</span>
<span class="sd">        :param torch.Tensor y: measurement :math:`y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bkg</span><span class="p">))</span></div>


<div class="viewcode-block" id="PoissonLikelihood.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the Poisson negative log-likelihood.</span>

<span class="sd">        :param torch.Tensor x: signal :math:`x` at which the function is computed.</span>
<span class="sd">        :param torch.Tensor y: measurement :math:`y`.</span>
<span class="sd">        :param float gamma: proximity operator step size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">x</span>
            <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">y</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span> <span class="o">/</span> <span class="mi">2</span></div>
</div>



<div class="viewcode-block" id="L1">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1">[docs]</a>
<span class="k">class</span> <span class="nc">L1</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :math:`\ell_1` data fidelity term.</span>

<span class="sd">    In this case, the data fidelity term is defined as</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = \|Ax-y\|_1.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="L1.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="L1.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gradient of the gradient of the :math:`\ell_1` norm, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \partial \datafid(x) = \operatorname{sign}(x-y)</span>


<span class="sd">        .. note::</span>

<span class="sd">            The gradient is not defined at :math:`x=y`.</span>


<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the gradient is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`x`.</span>
<span class="sd">        :return: (torch.Tensor) gradient of the :math:`\ell_1` norm at `x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="L1.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the :math:`\ell_1` norm, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\gamma \ell_1}(x) = \underset{z}{\text{argmin}} \,\, \gamma \|z-y\|_1+\frac{1}{2}\|z-x\|_2^2</span>


<span class="sd">        also known as the soft-thresholding operator.</span>

<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`x`.</span>
<span class="sd">        :param float gamma: stepsize (or soft-thresholding parameter).</span>
<span class="sd">        :return: (torch.Tensor) soft-thresholding of `u` with parameter `gamma`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">aux</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
            <span class="n">d</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">aux</span> <span class="o">+</span> <span class="n">y</span></div>


<div class="viewcode-block" id="L1.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">stepsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">crit_conv</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the :math:`\ell_1` norm composed with A, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\gamma \ell_1}(x) = \underset{u}{\text{argmin}} \,\, \gamma \|Au-y\|_1+\frac{1}{2}\|u-x\|_2^2.</span>



<span class="sd">        Since no closed form is available for general measurement operators, we use a dual forward-backward algorithm.</span>


<span class="sd">        :param torch.Tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y` of the same dimension as :math:`\forw{x}`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float stepsize: step-size of the dual-forward-backward algorithm.</span>
<span class="sd">        :param float crit_conv: convergence criterion of the dual-forward-backward algorithm.</span>
<span class="sd">        :param int max_iter: maximum number of iterations of the dual-forward-backward algorithm.</span>
<span class="sd">        :return: (torch.Tensor) projection on the :math:`\ell_2` ball of radius `radius` and centered in `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">norm_AtA</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">compute_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">stepsize</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">norm_AtA</span> <span class="k">if</span> <span class="n">stepsize</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">stepsize</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="n">u_prev</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_adjoint</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u_</span> <span class="o">-</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span><span class="n">u_</span> <span class="o">/</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">/</span> <span class="n">stepsize</span><span class="p">)</span>
            <span class="n">rel_crit</span> <span class="o">=</span> <span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_prev</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">rel_crit</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">rel_crit</span> <span class="o">&lt;</span> <span class="n">crit_conv</span> <span class="ow">and</span> <span class="n">it</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">t</span></div>
</div>



<div class="viewcode-block" id="AmplitudeLoss">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.AmplitudeLoss.html#deepinv.optim.AmplitudeLoss">[docs]</a>
<span class="k">class</span> <span class="nc">AmplitudeLoss</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Amplitude loss as the data fidelity term for :meth:`deepinv.physics.PhaseRetrieval` reconstrunction.</span>

<span class="sd">    In this case, the data fidelity term is defined as</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = \sum_{i=1}^{m}{(\sqrt{|b_i x|^2}-\sqrt{y_i})^2},</span>

<span class="sd">    where :math:`b_i` is the i-th row of the linear operator :math:`B` of the phase retrieval class and :math:`y_i` is the i-th entry of the measurements, and :math:`m` is the number of measurements.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="AmplitudeLoss.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.AmplitudeLoss.html#deepinv.optim.AmplitudeLoss.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the amplitude loss.</span>

<span class="sd">        :param torch.Tensor u: estimated measurements.</span>
<span class="sd">        :param torch.Tensor y: true measurements.</span>
<span class="sd">        :return: (torch.Tensor) the amplitude loss of shape B where B is the batch size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">d</span></div>


<div class="viewcode-block" id="AmplitudeLoss.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.AmplitudeLoss.html#deepinv.optim.AmplitudeLoss.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradient of the amplitude loss :math:`\distance{u}{y}`, i.e.,</span>

<span class="sd">        .. math::</span>

<span class="sd">            \nabla_{u}\distance{u}{y} = \frac{\sqrt{u}-\sqrt{y}}{\sqrt{u}}</span>


<span class="sd">        :param torch.Tensor u: Variable :math:`u` at which the gradient is computed.</span>
<span class="sd">        :param torch.Tensor y: Data :math:`y`.</span>
<span class="sd">        :param float epsilon: small value to avoid division by zero.</span>
<span class="sd">        :return: (torch.Tensor) gradient of the amplitude loss function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="LogPoissonLikelihood">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.LogPoissonLikelihood.html#deepinv.optim.LogPoissonLikelihood">[docs]</a>
<span class="k">class</span> <span class="nc">LogPoissonLikelihood</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log-Poisson negative log-likelihood.</span>

<span class="sd">    .. math::</span>

<span class="sd">        \datafid{z}{y} =  N_0 (1^{\top} \exp(-\mu z)+ \mu \exp(-\mu y)^{\top}x)</span>

<span class="sd">    Corresponds to LogPoissonNoise with the same arguments N0 and mu.</span>
<span class="sd">    There is no closed-form of prox_d known.</span>

<span class="sd">    :param float N0: average number of photons</span>
<span class="sd">    :param float mu: normalization constant</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N0</span><span class="o">=</span><span class="mf">1024.0</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="mf">50.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N0</span> <span class="o">=</span> <span class="n">N0</span>

<div class="viewcode-block" id="LogPoissonLikelihood.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.LogPoissonLikelihood.html#deepinv.optim.LogPoissonLikelihood.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">N0</span>
        <span class="n">out2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">N0</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">out1</span> <span class="o">+</span> <span class="n">out2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>
</div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">deepinv</span> <span class="k">as</span> <span class="nn">dinv</span>

    <span class="c1"># define a loss function</span>
    <span class="n">data_fidelity</span> <span class="o">=</span> <span class="n">L2</span><span class="p">()</span>

    <span class="c1"># create a measurement operator dxd</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
    <span class="n">A_forward</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">A_adjoint</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">v</span><span class="p">)</span>

    <span class="c1"># Define the physics model associated to this operator</span>
    <span class="n">physics</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">LinearPhysics</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">A_forward</span><span class="p">,</span> <span class="n">A_adjoint</span><span class="o">=</span><span class="n">A_adjoint</span><span class="p">)</span>

    <span class="c1"># Define two points of size Bxd</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute the loss :math:`f(x) = \datafid{A(x)}{y}`</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">)</span>  <span class="c1"># print f gives 1.0</span>
    <span class="c1"># Compute the gradient of :math:`f`</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">)</span>  <span class="c1"># print grad_f gives [2.0000, 0.5000]</span>

    <span class="c1"># Compute the proximity operator of :math:`f`</span>
    <span class="n">prox</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="o">.</span><span class="n">prox</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span>
    <span class="p">)</span>  <span class="c1"># print prox_fA gives [0.6000, 3.6000]</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>